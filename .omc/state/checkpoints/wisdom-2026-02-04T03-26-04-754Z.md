## Plan Wisdom

### phase6-testing/learnings.md
# Phase 6 Testing & Validation: Learnings

## Testing Approach

### Automated Validation Strategy
- **TypeScript Checking**: Essential first step - catches type errors before runtime
- **Production Build**: Verifies all pages can generate statically
- **Dev Server Check**: Confirms runtime behavior and SSR works
- **Source Inspection**: Validates CSS injection and component rendering

### Build Warnings vs. Errors
- **GitHub API Rate Limit**: Non-blocking warning, graceful fallback implemented
- **Empty Collections**: Expected warning when content directories exist but are empty
- **TypeScript Warnings**: Unused variables in generated D3 code are non-critical
- **Key Learning**: Distinguish between blocking errors and expected warnings

## Performance Validation

### What Can Be Automated
- Build time measurement (3.36s baseline established)
- TypeScript compilation speed (<2s is excellent)
- Bundle size tracking (scoped styles keep bundles small)
- Page generation count (6 pages verified)

### What Requires Manual Testing
- Visual rendering and animation smoothness
- Cursor interaction responsiveness
- Scroll animation performance
- Cross-browser compatibility
- Accessibility compliance

## Component Integration Testing

### CSS Scoping Verification
- Astro's scoped styles inject with unique data attributes
- Svelte components have their own scoping system (s-prefix hashes)
- Both systems coexist without conflicts
- Custom properties bridge the scoping boundaries

### Source Code Inspection Techniques
- `curl` to check rendered HTML validates SSR output
- `grep` for style tags confirms CSS injection
- Title tags verify page routing works
- Canvas elements confirm client-side components load

## Documentation Standards

### Test Report Structure
1. **Automated Results**: Build, type checking, server status
2. **Manual Checklists**: Visual regression, performance, accessibility
3. **Known Issues**: Document expected warnings vs. actual bugs
4. **Success Criteria**: Quantifiable pass/fail conditions
5. **Next Steps**: Clear action items for follow-up

### Evidence-Based Validation
- Never claim "looks good" without evidence
- Always include command output or source inspection
- Document both what passed AND what requires manual verification
- Distinguish between "tested" and "ready for manual QA"

## Deployment Readiness Criteria

### Minimum Bar for Staging
- ✅ TypeScript compilation passes
- ✅ Production build succeeds
- ✅ All configured pages generate
- ✅ No blocking errors
- ✅ Dev server runs successfully

### Recommended Before Production
- Manual visual inspection
- Lighthouse audit
- Cross-browser testing
- Accessibility verification
- Performance profiling

## Pattern Recognition

### Build Success Indicators
- "Complete!" message from Astro
- Page count matches expected routes
- No error stack traces (only warnings OK)
- Static assets generated in dist/

### Build Failure Indicators
- TypeScript compilation errors (not warnings)
- Missing dependencies
- Syntax errors in components
- Route generation failures

## Testing Efficiency

### Fast Feedback Loop
1. TypeScript check (fastest - 2s)
2. Dev server (fast - 5s startup)
3. Production build (medium - 3.4s)
4. Full validation suite (slowest - manual)

### When to Run What
- **Every edit**: Dev server hot reload
- **Before commit**: TypeScript check
- **Before PR**: Production build
- **Before deploy**: Full validation suite

## Phase Transition Strategy

### Completing a Phase
1. Run all automated checks
2. Document results in notepad
3. Update task status
4. Create summary report
5. Identify any blockers for next phase
6. Mark phase complete only when evidence confirms success

### Continuing vs. Completing
- If manual QA is optional: Document what's needed, mark complete
- If manual QA is required: Keep task in_progress until verified
- Always err on side of clear next steps over premature completion